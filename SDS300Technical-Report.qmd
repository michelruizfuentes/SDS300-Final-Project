---
title: "Investigating the Impact of Monetary Rewards on Choice Behavior, Decision Making and Risk Management"
author: "Michel Ruiz-Fuentes | Smith College"
format: pdf
editor: visual
date: "`r Sys.Date()`"
---

**Keywords**: behavioral and cognitive science, external stimuli, internal emotions, behavioral biases, interoceptive ability, dopamine reward pathway, loss aversion

# Abstract

What biological and social mechanisms influence our decision-making processes? Where do our judgment and rationale for our choices stem from, such as in the context of money management? Can a better understanding of these natural and social phenomena improve our finances? In this project, I investigated risk decisions and their implications for financial professionals such as investors, traders, or brokers. I am using the Choices13K data set, an open data source retrieved from GitHub that is among the most expansive human decision response on risk-choice problems datasets with at least 13,000 responses.

In this study, the participants participated in a series of experiments where they faced two options: a risk-averse or risk-seeking gamble. Each gamble had a different set of possible outcomes. For example, if they chose Gamble A, there was a certain probability of a 100% chance of a \$0 return (risk-averse); however, if they chose Gamble B, there was a lottery outcome with a 50-50% chance of winning or losing \$100 (risk-seeking). My research question studies if and how participants' responses to the risky-choice problem contrast when there are known probabilities (certainty) versus unknown probabilities (ambiguity and lottery).

I use neuroscience, psychology, and biology research to investigate the underlying processes that impact decision-making in the context of financial decisions and risk management. In neuroscience, I investigated how desire activates our neural reward and dopamine systems, which influences the limbic system and neocortex, where some decision-making occurs. The field of psychology demonstrates that behavioral biases and behavioral finance protocols help researchers observe how emotions and pleasure-seeking approach vs. loss aversion approach impact decision-making. And lastly, within the study of biology and decision-making, I studied interoceptive abilities and genetics, such as testosterone, and how the levels of each explain the nuances of financial decision-making. In my methodology, I perform a t-test, logistic regression, and a correlation matrix to respond to my research question.

# Introduction

### [**Background:**]{.underline}

What factors influence whether we become risk-averse, risk-seeking, or risk-neutral individuals? For example, in finance, risk-averse individuals seek low-risk investments to preserve capital. In contrast, risk-seeking individuals seek investments with a higher or unlimited degree of risk in hopes of producing a strong return. If we become informed about the various factors (neuroscience, psychology, and biology) that shape our risk tolerance, can this understanding improve our judgment and decision-making skills? In this research design, I investigate the factors influencing decision-making and run statistical tests on a risky-choice data set to test my hypothesis.

Psychologists Daniel Kahneman and Amos Tversky coined the risky-choice framing effect, and they also studied judgment and decision-making. Judgment is estimating (or guessing) magnitudes and probabilities, while decision-making is choosing under uncertainty. Kahneman and Tversky studied how humans responded to a series of risky-choice problems and discovered that risk perception was instrumental in influencing the participant's choice.

For example, if one gamble was framed positively for having a gain outcome, the subject preferred a risk-averse gamble. On the other hand, if another gamble was framed negatively for having a potential loss, the subject preferred a risk-seeking gamble. Individuals make choices dependent on the degree of risk involved, so my literature review is a multidisciplinary analysis of this phenomenon across various fields of study.

### [**Neuroscience:**]{.underline}

Neuroscience research indicates that several brain regions, such as the frontal lobe, limbic system, and dopamine reward system, are critical brain structures that help individuals rationalize the potential for gain or loss from a gamble. Decision-making is a neural process, so comprehending the brain's role begins at the fundamental level of understanding how each section of the brain is connected and communicates via neurons. Neurons are responsible for sending and communicating information with different brain regions. Glial cells support the nervous system by maintaining the neurons through structural supports, nutrients, and cleaning waste matter. The types of decisions and risks associated with a task will trigger specific neurons within the frontal lobe and limbic system to activate. Kahneman's book, "Thinking Fast and Slow" differentiates two operating systems in the brain for decision making as System 1 and system 2.

System 1 is composed of the limbic system consisting of the amygdala and hypothalamus. System 1 is fast and characterized by automatic, preconscious, driven by emotions and association, effortless, and with less self-awareness or control. It directs ninety-eight percent of all our thinking. The limbic system is primitive and vital to the heritage that has helped generations of humanity survive for generations. Because the limbic system is emotionally motivated, this sometimes indicates why individuals are more inclined to choose immediate gratification and make decisions based on the short term.Â 

The amygdala recognizes emotions such as pleasure and fear, so it is also critical in helping humans navigate and respond appropriately to social interactions---wet lab experiments concerning the amygdala test for changes in the expression and perception of fear. Damage to the amygdala looks like patients struggling with recognizing emotions and automatic responses to reward and punishment. For example, in an experiment concerning monetary gain or loss, a participant with damage to the amygdala will have trouble learning and remembering which gambles they should avoid due to being disadvantageous or less desirable, while healthy participants are aware of which gamble, they should choose to retain a reward.

The hypothalamus helps the body maintain stable homeostasis by managing hormones and connecting the endocrine and nervous systems. The hypothalamus manages breathing, sleep patterns, blood pressure, drive, body temperature, and other functions requiring control and balance. Hypothalamus damage will interfere with the body's internal balance and everyday functions.

System 2 comprises the neocortex, divided into four regions: frontal, parietal, occipital, and temporal. System 2 is slow and characterized by rational and logical thinking, sequential, conscious, skepticism, and self-awareness. It directs two percent of all our thinking. System 2 is informed by System 1, and System 2 converts this into beliefs, so we use both operating systems to create a final judgment.

The frontal lobe comprises 25-40% of the brain's cerebral cortex. It helps us fulfill task sets and manages a variety of abilities: reasoning, social understanding, executive functions, voluntary muscle movements, and learning. The frontal lobe supports, through reason, goal-oriented behavior such as solving problems, thinking, judging, executing a plan, and anticipating the consequences of a plan. The application of the frontal lobe in risk management is that inquiring about the longevity and future implications of one allows an individual to develop protocols and habits for decision-making based on their previous experiences making choices.

This region is also crucial for learning about memory and knowledge creation, storage, and retrieval. It supports executive functions such as self-control or attention and social understanding, which consists of social norms, ethics, and right versus wrong. The frontal lobe is not directly correlated to all decision-making, but this task will activate certain regions depending on the context and type of risk. Damage to the frontal lobe can hinder higher-level reasoning and decision-making. There is still much to explore about how the frontal lobe plays a role in decision-making under uncertainty or environmental situations that include changes or open-mindedness.

The dopamine reward system is a crucial system that drives behavior toward pleasurable stimuli and steers us away from painful stimuli. It is called reinforcement when we learn which actions receive a positive stimulus and repeat that action. Therefore, the reward system captures our emotions and reinforces whether we continue to perform or stop acting. The reward system operates on dopamine, a chemical neurotransmitter that mediates pleasure and neurochemical that drives us to start or repeat actions for a reward. One of the most crucial reward circuits is the mesolimbic pathway, a central nervous system pathway activated during rewarding brain stimulation involving the amygdala, amygdala, hypothalamus, and nucleus accumbens. Therefore, various brain regions work cohesively to mediate the desire to act on rewarding behaviors and the release of dopamine.

### [**Psychology:**]{.underline}

Next will be an analysis of the psychological basis of judgment and how behavioral biases and our emotions affect decision-making. We will study this judgment protocol based on investor behaviors since their careers involve making constant decisions that either result in a monetary gain or loss. Behavioral biases refer to individuals making decisions based on factors and/or beliefs they subconsciously possess or have heard of, affecting their ability to choose rationally. Researchers across social sciences, economics, psychology, etc., all categorize these biases uniquely, sometimes into two, five, or seven categories.

The CFA Institute is a non-profit educational organization that trains investment professionals, and I will use their categorization of behavioral biases since my data set concerns choices and monetary rewards. The CFA groups behavioral biases into two divisions: cognitive errors and emotional biases. Cognitive errors refer to faulty reasoning, which stems from individuals having memory errors; emotional biases refer to reason influenced by feelings and intuition. Because emotional biases stem from an internal impulse, they are more challenging to separate in decision-making than cognitive errors. If behavioral biases refer to the unconscious (cognitive or emotion-based) beliefs that influence our decisions, what is the utility of this phenomenon for investors?

Behavioral finance studies the psychological influences and biases of behaviors that affect financial professionals such as investors. It is a relatively new study of thinking, merging psychology and biology. Before the 1960s, economists believed humans behave logically; however, history across multiple disciplines indicates this to be false. Despite having data and evidence to suggest an outcome, we sometimes act against that knowledge. An article published by Morgan Stanley in Jan 2023 titled [Rational Investing in an Age of Uncertainty](https://www.morganstanley.com/articles/behavioral-finance) questions how even the savviest of investors fall prey to bias and emotional trades. Behavioral finance tackles these questions and has the potential to explain market anomalies such as the stark increase or drops in stock prices. Understanding cognitive error and emotional biases also informs investors about the factors that cloud their judgment and may serve as a tool to create more conscious and critical investors, but how does behavioral finance achieve this?

Behavioral finance introduces psychological frameworks as evidence to demonstrate how humans are not ultimately always rational. These frameworks include the loss aversion or reward approach. The reward approach observes how gain is enticing and, thereby, a pleasure-seeking option, while loss aversion is a pain avoidance framework that weighs loss to be more painful and ultimately perceives it as a form of punishment. Loss aversion is a strong emotion because it induces anxiety, stress, and fear of loss, and you may notice this within yourself if you observe your setbacks more than your progress. Those individuals might also agree with Kahneman, who described losses as hurting twice as much as gains making us feel pleasure. Loss aversion shapes higher sensitivity to loss compared to risk-averse individuals that are less sensitive to choosing under uncertainty of gain or less.

On the other hand, the reward approach is a natural process in the brain that associates stimuli such as situations, events, or behaviors with a desirable outcome and is known as the pleasure-seeking option. Although this creates more risk-averse individuals that chase the stimuli that produce positive outcomes, their judgment is skewed. Although this makes more risk-averse individuals chase the stimuli that produce positive outcomes, their judgment can be impaired if they associate the stimuli with a desired outcome based on cognitive errors or emotional biases that are not grounded in evidence. Suppose the judgment is associated the stimuli with a desired outcome based on cognitive errors or emotional biases that are not grounded in evidence.

The reward approach and loss aversion framework are two systems that influence investor behavior. Their psychological biases influence decision-making, so understanding them can help investors separate cognitive errors and emotional biases from making rational decisions, as well as allow them to identify if they operate using a loss-aversion or reward approach more frequently or both depending on the object being risked whether it be money, another intangible or intangible such as risking time.

### [**Neurobiology:**]{.underline}

The psychological basis of behavioral biases shows that emotions play an integral part in rational decision-making and trigger a changing heartbeat. Boussaert's piece, "How Neurobiology Elucidates the Role of Emotions in Financial Decision-Making," suggests that studying decision-making based on the biology of behaviors will debunk misconceptions about the role of emotions and explore features that are not traditionally considered when observing human choices. Neurobiology merges physiology and neuroscience by studying the nervous system and brain and the biological mechanisms that mediate behavior. In Boussaert's research, neurobiology uses underlying biological mechanisms to explain feelings that arise during judgment and decision-making, such as going with your "intuition" or "gut feeling" using interception. Interoception refers to the ability to identify, interpret and respond to internal physiological signals such as pain, hunger, and in this case, heartbeat.

Possessing interoceptive abilities suggests the person shows high levels of consciousness of their body's internal landscape. Boussaert's research demonstrates that traders that cannot sense their heartbeat and control their emotions in high-risk settings are at risk of underperforming, while traders that can sense their heartbeat and manage their emotions that consequently affected their heartbeat were better traders than the large population. Therefore, they positively correlated levels of interoceptive ability with performance profits/loss and job tenure. In addition, traders that can sense their heartbeat are better at making capital.

Another physiological factor that corresponds to investor behavior, financial decision-making, and success rates is genetics due to their biological functions. For example, testosterone is a hormone responsible for producing sex and reproductive characteristics in men that contrasts in muscle density, body hair, bone size, etc. Both sexes produce this androgen, but men make it at higher levels, and testosterone is converted into estrogen in women. However, 6% to 10% have high levels of testosterone and polycystic ovary syndrome (PCOS), characterized by symptoms such as irregular or no periods, excessive hair growth, and other traits. Testosterone is also associated with aggression, competitiveness, and risk-taking, and more testosterone is associated with greater risk-taking.

Studying the notion of financial decisions and risk management is interconnected, so observing the correlations between testosterone levels and behavioral biases alludes to how sex may impact risk appetite. Additionally, in another study about financial risk and testosterone levels by Apicella, the researchers found that levels of testosterone were associated with greater risk-taking, so having a more significant risk tolerance can influence longevity, success rate, and opportunities in a career if the individual is more willing to take the chances under uncertainty. The following multidisciplinary research concludes that understanding the nuances of financial decisions and risk management requires considering the interplay between neural networks, behavioral biases, emotions, and biology.

\newpage

# Methodology

### [**Research Question:**]{.underline}

***Original:*** How do the participant's responses to the risky-choice problem contrast with known probabilities (certainty) versus unknown probabilities (ambiguity and lottery)?Â 

***Revised due to data set limitations:*** How do the participant's responses to the Gamble B risky-choice problem, with unknown probabilities (ambiguity and lottery), contrast when the participant receives the feedback (`Feedback)` or information (`Amb`) treatment?

### [**Hypothesis:**]{.underline}

The null hypothesis states there is no difference in the mean score of participants' choice of Gamble B (`bRate`) depending on whether they receive feedback or information about the outcomes of the variables. Therefore, the true difference between the group means would be zero to indicate the means are the same and do not change based on the treatment provided; treatment being the feedback or information levels.

The alternative hypothesis states at least one different mean score of participants' choice Gamble B (`bRate`) depending on whether they receive feedback or information about the outcomes of the variables. The true difference between the group means would contrast and therefore not include zero to indicate the means vary based on the treatment provided, the treatment being the feedback or information levels.

Based on the literature, I support the alternative hypothesis and believe there will be a difference in the mean score of participant's choice of Gamble B (`bRate`) depending on the treatment and level provided: whether they receive `Feedback` (receive or did not receive) or `Amb` (none or complete information). Kahneman and Tversky's research on decision-making and risk perception indicates that the feedback and perception used to frame risky-choice problems influence the participant's choice. For example, if one gamble was framed positively for having a gain outcome, the subject preferred a risk-averse option. On the other hand, if another gamble was prepared negatively for potential loss, the subject preferred a risk-seeking option.

\newpage

### [**Data set:**]{.underline}

```{r, echo = FALSE, warning=F, message=F}
#LOADING_PKGE
library(tidyverse)
library(rio)
library(asbio)
library(tidyr)
library(ggplot2)
library(ggpubr)
library(car)
library(corrplot)
library(gtsummary)
```

```{r, warning=F, message=F}
#LOADING_DATA
choices_df <- import("choices13k_dataset.xlsx")
```

The [Choices13k data set](https://github.com/jcpeterson/choices13k) was collected by Joshua C. Peterson, David D. Bourgin, Mayank Agrawal, Daniel Reichman, and Thomas L. Griffins and published on GitHub. In this study, participants engaged in a series of risky-choice problems.Â 

Choices13k is among the largest human decision rates on risky-choice problems datasets, with at least 13,000 responses. In this study, participants received a risky-choice problem with one of two gambles, and each option had a different possible outcome. In Gamble A, there was a certain probability of a 100% chance of \$0, so this was the risk-averse option. However, in Gamble B, there was a lottery outcome of a 50-50 chance of winning or losing \$100, which was the risk-seeking option.

In the original experiment, the data set built quantitative models in machine learning to predict human behavior. However, due to the complexity of many factors (neuroscience, psychology, biology, etc.) that underly decision-making, the researchers struggled to build a model that accurately predicted human judgment. Therefore, because my project utilizes statistical methods to understand better how feedback and certainty impact decision-making, this is not a replication study of the original researchers who focused on using Choices13K for machine learning purposes.

### [**Ethical Considerations:**]{.underline}

The replication crisis refers to a lack of reproducibility in experimental designs and the scientific method. Therefore, assessing the data for ethical considerations such as the replication process is critical; otherwise, integrity issues arise. For example, say one investigator is trying to repeat the research design of another scientist, but they cannot produce the same results as the original study. The replication crisis occurs when inconsistencies and manipulations are not reported in the research design. These experiments than have misleading and sometimes favorable results that are not indicative of the true results of the experiment.

However, to solve this issue, researchers can pre-register their study. Preregistration refers to a set of protocols that support "open science," which is reproducible, accessible, transparent, and rigorous. Overall, "open science" principles allow for best and ethical practices for research. Preregistration consists of criteria that help mitigate the threats of unethical scientific practices and encourage the responsible conduct of research.

First, consolidating the research methodology and process before the experiment makes the researcher less likely to change their methods to skew their results because they are following the experiment sequence they designed beforehand. I fulfilled this procedure by developing my research question, conducting my background research, and developing my hypotheses before the experiment. The research question guided my investigations to consolidate the types of statistical tests (t-test, ANOVA, logistic regression) I should perform to test my question.

Second, by conducting background research about the theory to develop a hypothesis, the author uses literature to develop a prediction and will not create their hypothesis after running the results; otherwise, their predictions will always be true. Therefore, to develop my hypothesis, I researched the neuroscience, psychology, and biology of decision-making, including the role of confounding variables. Finally, I stated the null and alternative hypotheses and correlated the literature with the alternative hypothesis.

Third, having a public repository of the data and code for the analyses allows for the accessibility and reproducibility of the experiment. All of my code, literature, and citations are available on GitHub. Fourth, by discussing model limitations and condition checks, such as whether random sampling and random assignment were achieved for this study, the investigator is transparent about their data and the application of their findings to the real world. I will pursue this in my study's discussion and future directions section. And lastly, by emphasizing the substantive importance of the results in addition to the statistical interpretation and significance, they have demonstrated a rigorous and comprehensive understanding of their results.

Therefore, in conclusion, some preregistration methods consist of registering the research method and report, developing a hypothesis before testing it, opening data/code, discussing limitations, and understanding the application of the results. These methods make reproducible, accessible, transparent, and rigorous "open science," so I will follow this method for my project.

### [**Data Cleaning:**]{.underline}

During this data pre-processing stage, I checked for missing values and removed and corrected any errors/inconsistencies and data types. However, because this data was used for a machine-learning project, the data was relatively accessible and clean, and I will be using it for statistics and results purposes. Most of my cleaning arose from changing data types to fit my analyses.

### [**Variables of Interest:**]{.underline}

![Choices 14k Dataset Variables](sds300-table.jpg){alt="Choices 14k Dataset Variables"}

\newpage

# **Statistical Methods**

### [T-Test:]{.underline}

In a t-test, the researcher determines if there is a significant difference between the means of the two groups. The t-test calculates a t-value and compares this to the critical value to show if the difference is statistically significant.

For example, the ANOVA and t-test will both be used to assess if there is a statistically significant difference in the frequency rate of choosing Gamble B (`bRate`) dependent on the information (`Amb`) or feedback (`Feedback`) provided. It compares the averages of the dependent variable and investigates if the averages contrast with the treatment provided.

### [One-Way Anova:]{.underline}

One-Way ANOVA looks at the means of more than two groups and calculates the f-statistic as well to measure the between-group variation over the within-group variation. Therefore, if this example, if there is no significant difference on bRate based on the `Amb` and/or `Feedback`, then we do not have statistically significant explanatory power. In other words, the bRate will remain the same based on the information (`Amb`) or feedback (`Feedback`) provided.

### [Box plot:]{.underline}

Because I will run a t-test and One-Way ANOVA to compare group means, the box plot will help visualize the distribution of the data and any potential outliers or skewness. It will demonstrate the distribution of probabilities for Gambles A and B, with separate boxes for each. The box plots will visualize the distribution of the outcome variable (`bRate`) across different categorical variable levels (e.g., `feedback`, `Amb`) to check for mean differences.

### [Logistic Regression:]{.underline}

This statistical method predicts the outcome of `bRate` (dependent variable) based on the previous observations, `Feedback`, or `Amb`. Researchers use logistic regression plots to visualize the relationship between the predictor variables (e.g., `Feedback`, `Amb`) and the binary outcome variable (`bRate` of chosen Gamble B) to check for significant effects and to interpret the odds ratios. For example, if the p-value is below 0.05, we would reject the null and determine evidence for a statistically significant difference, but if it is above 0.05, then we fail to reject the null.

### [**Levene's Test:**]{.underline}Â 

Levene's test is designed to test a hypothesis, so a significant p-value indicates that we failed to reject the null and that the groups have homogeneity. This is evidence that the population variances are not significantly different, and we have constant variance among the groups. This is one of the approaches to test the assumptions of normality for the ANOVA and t-test.

### [**Correlation Matrix:**]{.underline}Â 

#### Correlation Matrix Table

The correlation matrix table contains the correlation coefficients between each variable and the others that illustrates the dependence between multiple variables simultaneously.

#### Correlation Matrix Plot

The correlation matrix plot will visualize the pairwise correlations between all continuous variables in the data set to check for multicollinearity. I will make a matrix plot with variables `Ha`, `pHa`, `La`, `Hb`, `pHb`, `Lb`, `Corr`, `bRate` to assess for multicollinearity where 0 indicates the values have no linear relationship between two continuous variables, and a coefficient of -1/-1 indicates there is a perfect -/+ linear relationship. A linear relationship would suggest the two different variables are associated, and the degree of their changes impact each other.

#### Correlation Matrix Heat Map

Heat maps to visualize the relationship between two categorical variables or mapping the continuous variables to check for any patterns or associations.

\newpage

# **Results**

The results section will consist of multiple statistical tests and data visualizations.

### [**T-Test for `bRate` and `Feedback`:**]{.underline}

Utilizing a t-test to assess if there is a statistically significant difference between the mean **`bRate`** \[the frequency of choosing Gamble B\] between the the true and false groups of whether the participants received **`Feedback`** on the outcome.

The p-value is above 0.8441, so we fail to reject the null hypothesis which states there is no difference in the frequency with which participants select **`bRate`** depending on their treatment of whether they had **`Feedback`** about the outcomes.

Additionally, the confidence interval shows that we are 95% that our true population parameter falls within \[-0.011334634, 0.007675331\]. This confidence interval includes zero which demonstrates that the true population parameter could be zero and the mean frequency rate of choosing Gamble B would be the same regardless of the **`Feedback`** about the outcome.

```{r, warning=F, message=F}
# Running a t-test for bRate and Feedback
choices_df$Feedback <- as.factor(choices_df$Feedback)
t.test(bRate~Feedback, data=choices_df)
```

### [**One-Way ANOVA for `bRate` and `Feedback`:**]{.underline}

Because our p-value for `Feedback` is 0.713 (greater than 0.05), and we have a small F-statistic of 0.1354635, we do not have statistically significant evidence that the `bRate` is different based on the `Feedback` received. Therefore, we do not have a main effect on `Feedback`.

```{r, warning=F, message=F}
# Run one-way ANOVA against feedback
choices_df$Feedback <- as.factor(choices_df$Feedback)
feedback_anova <- aov(bRate ~ Feedback, data = choices_df)

# Summarize ANOVA results
summary(feedback_anova)
f_statistic <- summary(feedback_anova)[[1]][["F value"]][1]
p_value <- summary(feedback_anova)[[1]][["Pr(>F)"]][1]

# Print F-statistic and p-value
cat("F-statistic =", f_statistic, "\n")
cat("p-value =", p_value, "\n")
```

### [**Condition Checks for `bRate` and `Feedback`:**]{.underline}

#### [**Symmetrical Distribution around Group Means**]{.underline}:

The box plot below shows us the distribution of the average rate on the different levels of `Feedback` of true or false. Next, we will compare the variation in the interquartile ranges of each treatment. We can see that this condition is not violated when looking at the spread in the false and true groups of `Feedback` are the same. There is also an absence of outliers, so we have not violated these normality assumptions.

By looking at the plot, we can see that the constant variance condition is not violated. This is because we have constant variance across the true and false groups. However, checking conditions with visualizations can be tricky, so we can refer to Levene's test to check our constant variance condition.

```{r, warning=F, message=F, fig.height=2.5}
# Creating a boxplot visualization for bRate and Feedback
bRate_feedback <-
  ggplot(data=choices_df, aes(x=bRate, color=Feedback)) + 
  geom_boxplot() + 
  labs(title ="Frequency of Gamble B ('gamble') Box Plot",
      subtitle= "Assessing Distribution by Feedback Level",
      caption ="source: Choices13K") +
  xlab("Probability of Gamble B (0-impossible, 1-certain)") +
  ylab ("Feedback Rate") 
bRate_feedback
```

#### [**Constant Variance:**]{.underline}

After conducting Levene's test of homogeneity of variance, we see that our p-value of 0.2869 is greater than 0.05. This means that we do not have statistically significant evidence that we have different variances; therefore constant variance condition is not violated. Thus, Levene's test indicates that the condition of equality of variances has homogeneity, so each level of information, false and true, has the same variance.

```{r, warning=F, message=F}
# Levene's Test
leveneTest(bRate~Feedback, data=choices_df) 
```

Because neither the symmetric conditions around group means, normal distribution, nor constant variance has been violated, we do not need to perform the non-parametric method, Wilcoxon Man Whitney Test.

### [**T-Test for `bRate` and `Amb`:**]{.underline}

Utilizing a t-test to assess if there is a statistically significant difference between the mean `bRate` depending on the `Amb`. This refers to the differences between the true and false groups of whether the participants received complete information or no information about the probabilities of the outcomes in Gamble B.Â 

The p-value is above 2.2e-16, which is below 0.05, so we reject the null hypothesis, which states there is no difference in the frequency with which participants select bRate depending on their treatment of whether they had received no information or complete information about the probabilities of the outcomes in Gamble B.

Additionally, our confidence interval shows that we are 95% that our true population parameter falls within \[0.5090787, 0.5582683\] and does not include zero. This demonstrates that the true population parameter will not be equal to zero, and the mean frequency rate of `bRate` is statistically different based on `Amb` or the amount of information (none of complete) provided about the probabilities of each outcome occurring in Gamble B.

```{r, warning=F, message=F}
# Running a t-test for bRate and Amb
choices_df$Amb <- as.factor(choices_df$Amb)
t.test(bRate~Amb, data=choices_df)
```

### [**One-Way ANOVA for `bRate` and `Amb`:**]{.underline}

Because our p-value for `Amb` is 2e-16\*\*\* (less than 0.05), and we have a large F-statistic of 112.4 and have statistically significant evidence that the `bRate` is different based on the `Amb` (informed level) received. We there have main effect for `Amb`.

```{r, warning=F, message=F}
# Run one-way ANOVA against information 
info_anova <- aov(bRate ~ Amb, data = choices_df)

# Summarize ANOVA results
summary(info_anova)

# Extract F-statistic and p-value
f_statistic <- summary(info_anova)[[1]][["F value"]][1]
p_value <- summary(info_anova)[[1]][["Pr(>F)"]][1]

# Print F-statistic and p-value
cat("F-statistic =", f_statistic, "\n")
cat("p-value =", p_value, "\n")
```

### [**Condition Checks for `bRate` and `Amb`:**]{.underline}

#### [**Symmetrical Distribution around Group Means**]{.underline}:

The box-plot below shows us the distribution of the average `bRate` on the different levels of `Amb` of true or false which represent whether participants received complete or no information about their gambles before choosing the gamble. We will compare the variation in the interquartile ranges of each treatment. We can see that this condition is not violated, when looking at the spread in the false and true group are the same. There is also an absence of outliers so we have not violated these normality assumptions.

By looking at the plot, we can see that the constant variance condition is not violated. We have constant variance across the true and false groups. However, checking conditions with visualizations can be tricky, so we can refer to Levene's test to review our constant variance condition.

```{r, warning=F, message=F, fig.height=2.5}
# Creating a boxplot visualization for bRate and Feedback
bRate_Amb <-
  ggplot(data=choices_df, aes(x=bRate, color=Amb)) + 
  geom_boxplot() + 
  labs(title ="Frequency of Gamble B ('gamble') Box Plot",
      subtitle= "Assessing Distribution by Information Level",
      caption ="source: Choices13K") +
  xlab("Probability of Gamble B (0-impossible, 1-certain)") +
  ylab ("Frequency Rate") 
bRate_Amb
```

#### [**Constant Variance:**]{.underline}

After conducting Levene's test of homogeneity of variance, we see that our p-value of 0.5232 is greater than 0.05. This means that we do not have statistically significant evidence that we have different variances; therefore constant variance condition is not violated. Thus, Levene's test indicates that the condition of equality of variances has homogeneity, so each level of information, false and true, has the same variance.

```{r, warning=F, message=F}
# Levene's Test
leveneTest(bRate~Amb, data=choices_df)
```

### [**Logistic Regression on `pHa` and `Feedback`:**]{.underline}

The table below summarizes a logistic regression that models the presence of `pHa` using `Feedback` as a predictor; the coefficient of `pHa` is 0.01387. The p-value is not statistically significant, so our model suggests that `Feedback` does not impact the probability of the first outcome occurring in Gamble A, `pHa`.

However, if this were statistically significant, we would state that there is an increase in the probability of the first outcome occurring in Gamble A, `pHa` based on `Feedback` because the coefficient is positive. Specifically, the feedback group has 1.0143 times the odds of the non-feedback groups of getting the probability of the first outcome occurring in Gamble A, `pHa`.

```{r, warning=F, message=F}
# create logistic regression model for feedback and pHa
Afeedback_model <- glm(Feedback~pHa, data = choices_df, family = binomial())
tbl_regression(Afeedback_model)
#(e^0.01387 = 1.01396) CALCULATING ODDS RATIO
```

The logistic regression plot below shows `pHb` on the x-axis and `Feedback` on the y-axis, grouped by `Feedback` and colored by the levels of `Feedback`. It also includes a logistic regression line using the stat_smooth function with method = "glm" and family = "binomial." Finally, it visualizes the relationship between the `Feedback` (predictor variable) and the binary outcome variable of `pHa`. The data spread is evenly distributed and not significantly different, indicating that true and false feedback levels do not impact the probability of the first outcome occurring in Gamble A, `pHa`.

```{r, warning=F, message=F, fig.height=2.5}
# create logistic regression plot
ggplot(choices_df, aes(x = pHb, y = Feedback)) +
  geom_point(aes(color = as.factor(Feedback)), size = 2.5) +
  stat_smooth(method = "glm", method.args = 
                list(family = "binomial"),  
                size = 1.2, color = "black") +
  labs(title ="Logistic Regression Plot",
      subtitle= "Assessing Spread by Feedback Level",
      caption ="source: Choices13K") + 
  scale_color_manual(values = c("#00BFC4", "#F8766D")) 
```

### [**Logistic Regression on `pHb` and `Feedback`:**]{.underline}

The table below summarizes a logistic regression that models the presence of `pHb` using `Feedback` as a predictor; the coefficient of `pHb` is 0.08093. The p-value is not statistically significant, so our model suggests that `Feedback` does not impact the probability of the first outcome occurring in Gamble B, `pHb`.

However, if this were statistically significant, we would state that there is an increase in the probability of the first outcome occurring in Gamble B, `pHb` based on `Feedback` because the coefficient is positive. Specifically, we would states that the `Feedback` group has 1.084 times the odds of the non-Feedback groups of getting the probability of the first outcome occurring in Gamble B, `pHb`.

```{r, warning=F, message=F}
# create logistic regression model for feedback and pHa
Bfeedback_model <- glm(Feedback~pHb, data = choices_df, family = binomial())
tbl_regression(Bfeedback_model)
#(e^0.08093 = 1.08429) CALCULATING ODDS RATIO
```

The logistic regression plot below shows `pHb` on the x-axis and Feedback on the y-axis, grouped by `Feedback` and colored by the levels of `Feedback`. It also includes a logistic regression line using the stat_smooth function with method = "glm" and family = "binomial". It visualizes the relationship between the `Feedback` (predictor variable) and the the binary outcome variable of `pHb`. The data spread is evenly distributed and not significantly different indicating that `feedback` levels of true and false do not impact the probability of the first outcome occurring in Gamble B, `pHb`.

```{r, warning=F, message=F, fig.height=2.5}
# create logistic regression plot
ggplot(choices_df, aes(x = pHa, y = Feedback)) +
  geom_point(aes(color = as.factor(Feedback)), size = 2.5) +
  stat_smooth(method = "glm", method.args = 
                list(family = "binomial"),  
                size = 1.2, color = "black") +
  labs(title ="Logistic Regression Plot",
      subtitle= "Assessing Spread by Feedback Level",
      caption ="source: Choices13K") + 
  scale_color_manual(values = c("#00BFC4", "#F8766D")) 
```

### [**Correlation:**]{.underline}

In the correlation matrix table below, the correlation coefficients are visualized. This matrix is used to plot and visualize the correlation coefficients on a scale from -1 to 1.

```{r, warning=F, message=F, echo=FALSE}
# Making a df with just continous variables
choices_continuous <-
  choices_df |> select ("Ha", "pHa", "La", "Hb", "pHb", "Lb", "Corr", "bRate")
# Calculate the pairwise correlations between continous variables
corr_matrix <- cor(choices_continuous)
corr_matrix
```

In the correlation matrix plot below, the probabilities of the outcomes in Gamble A are correlated, as well as the probabilities of the outcomes in Gamble B. For example, `pHa` and `La` have a linear relationship, just as `Hb`, `pHb`, and `Lb` have a linear relationship. Therefore we can conclude that the probabilities of receiving the first or second outcome within a gamble are correlated.

```{r, warning=F, message=F, fig.height=5}
# Create a correlation matrix plot using the "corrplot" package
corrplot(corr_matrix, method = "circle", type = "upper", 
         tl.col = "black", tl.srt = 45,
         addCoef.col = "black", number.cex = 0.8, tl.cex = 0.8,
         title = "Pairwise correlations between continuous variables")
```

In the heat map below, the darker colors signify a father coefficient from 0, and the lighter the shade of blue, the closer a coefficient is to zero. For example, the darkest squares have a coefficient of 1 and and they demonstrate a strong linear relationship between the continuous variables and themselves: `pHb`-`pHb`, `Ha`-`Ha`, `pHa`-`pHa`, `Corr`-`Corr`, `bRate`-`bRate`, `Hb`-`Hb`, `Lb`-`Lb` and `La`-`La`. Next, there are linear relationships between `pHb`, `Hb`, and `Lb`, and a linear relationships between `pHa` and `Ha` which all demonstrate that the probability distributions of the first and second outcome in each Gamble A or B are associated.

```{r, warning=F, message=F, fig.height=5}
palette = colorRampPalette(c("blue", "lightblue", "navy")) (20)
heatmap(x = corr_matrix, col = palette, symm = TRUE)
```

\newpage

# Discussion

In this project, I investigated the research question, How do the participant's responses to the risky-choice problem contrast with known probabilities (certainty) versus unknown probabilities (ambiguity and lottery)? I hypothesized there would be at least one difference in the average rate of choosing either Gamble A or Gamble B depending on `Feedback`, whether the participant received feedback on the outcome of their variable. I also hypothesized there would be at least one difference in the average rate of choosing either Gamble A or B depending on `Amb`, whether or not the decision-maker received complete information about the probabilities of the outcomes.

Unfortunately, my data had various limitations, such as only having the frequency choice rate for one option, Gamble B. The data included `bRate`, which was the frequency with which participants selected Gamble B. However, there was not a variable that measured the frequency with which participants Gamble A. Instead, there were numerous probabilities variables such as `Ha`, `pHa`, `La`, `Hb`, `pHb`, and `Lb`, representing the probabilities of the first, expected, or lottery outcomes occurring in Gamble A or B. Because there was no variable measuring the frequency with which participants selected Gamble A, I could only run the t-test and One Way ANOVA for bRate based on the `Amb` and `Feedback` being the risk-seeking option. Therefore I had to change my research question since I could only test Gamble B.

My new hypothesis was that the true difference between the group means would not equal zero because the average choice rate for Gamble B (`bRate`) would contrast based on the treatment. I tested this research question using a t-test and One-Way ANOVA to determine whether there were any statistically significant differences between the means. I then used a box plot to visualize the averages across the different levels of `Amb` and `Feedback`. My new research question became, How do the participant's responses to the Gamble B risky-choice problem, with unknown probabilities (ambiguity and lottery), contrast when the participant receives the feedback (`Feedback)` or information (`Amb`) treatment.

I utilized a t-test and ANOVA to assess if there was a statistically significant difference between the mean **`bRate`** \[the frequency of choosing Gamble B\] between the true and false groups of whether the participants received **`Feedback`**. True indicates they received feedback on the outcomes of the variable, and false indicates they did not. The t-test failed to reject the null hypothesis, so the difference between the mean score of the participant's choice of bRate remains constant despite the treatment level of `Feedback` provided. Therefore, the mean frequency rate of choosing Gamble B, `bRate` would be the same regardless of the **`Feedback`** about the outcome. Additionally, the ANOVA demonstrates a small F-statistic of 0.1354635; we do not have statistically significant evidence that the bRate differs by Feedback level. In conclusion, we do not have a main effect on `Feedback` on `bRate`.

I also utilized an ANOVA and t-test to assess if there was a statistically significant difference between the mean **`bRate`** between the true and false groups of `Amb`, and whether or not the decision-maker gets complete information about the probabilities of the outcomes in Gamble B. Where 0 indicates complete information, so it is True, and 1 indicates no information so it is False. The t-test rejected the null hypothesis, so at least one different mean score of the participant's choice of `bRate` occurs due to the treatment level of information `Amb` provided. Therefore, the mean frequency rate of choosing Gamble B, bRate depends on the `Amb` about the probability of the outcome. Additionally, the ANOVA demonstrates a large F-statistic of 112.4, so we have statistically significant evidence that the bRate differs by information level or `Amb`. In conclusion, we have a main effect for `Amb` on `bRate`.

The results of testing the `Amb` treatment reinforce the literature insights about the loss aversion effect within behavioral finance, our dopamine reward system, and emotions. Thereby showing how neuroscience, psychology, and biology can explain why receiving no information or complete information about the probabilities of the outcomes (`Feedback`) in Gamble B presents statistically significant evidence in impacting the frequency of choosing Gamble B (`bRate`).

The loss aversion effect is a pain avoidance framework characterized by strong emotions such as anxiety, stress, and fear. Because Gamble B deals with more unknown probabilities (ambiguity and lottery) than Gamble A with known probabilities, the loss aversion framework is more likely to ignite in Gamble B. This framework considers loss to be more painful than the chances of getting pleasure during uncertainty and ultimately perceives the losses to be forms of punishment. Therefore in the context of information levels for `Amb`, individuals are more likely to fear the false option with no information about the probabilities of the outcomes of Gamble B, compared to the true option with complete information. Individuals that are impacted stronger by the loss aversion framework than the pleasure-seeking framework may notice that they tend to observe their setbacks more than their progress. Kahneman also describes their losses to hurt twice as much as their gains. Loss aversion shapes higher sensitivity to loss compared to risk-averse individuals that are less sensitive to choosing under uncertainty.

The dopamine reward system is a crucial system that drives behavior toward pleasurable stimuli and steers us away from painful stimuli. For example, we will repeat actions associated with a positive stimulus. This system, therefore, values our emotions and uses it as a predictor of whether we will reinforce the stimulus by repeating or discontinuing the action that produced said consequence. Because the dopamine reward system operates on dopamine, a neurochemical that mediates pleasure, our emotions are strongly correlated to our decision-making. In addition to emotions, decision-making uses rationale and evidence to develop judgment. Therefore, stronger evidence about the outputs depending on the information levels provided will also provide the choices made under uncertainty about Gamble B. In conclusion, although `feedback` level did not have statistically significant evidence of impacting the frequency rate with which participants chose Gamble B, information level or `Amb` did have statistically significant evidence of impacting the average `bRate`.

\newpage

# Future Directions

Based on the data set provided and the revisions required for my research question, and hypothesis, the first revision I recommend for this data set and experiment starts with computing the frequency with which participants selected Gamble A to compare against `bRate`. With this revision, I would have been able to test my original research question about how receiving various levels of `Feedback` or information (`Amb`) impacted the frequency rate of choosing Gamble A (risk-averse) and Gamble B (risk-seeking option); however, in this test, I was only able to test the risk-seeking option of `bRate`.

Second, the researchers of the Choices13k data set could talk more about whether there was random sampling to show if we can draw population inferences or develop generalizable insights. Additionally, they could specify if they randomly assigned the treatment because although they stated that this was an experimental design, clarifying if there was a random assignment for the treatments could further confirm if this was an experiment. Thirdly, in their methodology, they could have included their preregistration methods and ethical considerations, which consist of registering the research method, developing a hypothesis before testing it, open access to data/code, discussing limitations, and understanding the application of the results to keep the investigators accountable for making reproducible, accessible, transparent, and rigorous "open science."

Another approach that future investigations could pursue to continue this work would be to widen the data collection by expanding their variables of interest. For example, this data set provided variables such as the problem ID, number of participants, probabilities for outcomes in Gamble A and B, and the treatments feedback and information, in addition to other variables that were not prevalent for my analyses (`LotShapeB`, `Block`, etc.). It would have been highly beneficial to have a column that stated the problem the participants responded to instead of just the problem ID to see the language used to present the question and Gamble A and B. Additionally, it would have been helpful to have columns for the type of `Feedback` and information (`Amb`) level to show how each level was presented and therefore received perception. For example, Kahneman and Tversky's research proved that the presentation of the treatment and whether it be a positive or negative attitude plays a pivotal role in how it affects the participant's likelihood of choosing a gamble, so having this additional information would have allowed me to create a precise and concise hypothesis because I would have had more details on the feedback and information levels.

And lastly, the literature demonstrates that various factors from neuroscience, psychology and biology would provide explanatory power and novel results that can better answer my research question. Therefore, I recommend more variables to be added. For example, I would incorporate fMRI data from the neuroscience perspective to show which brain regions and neural activity are activated during the dopamine reward pathways. I will investigate if this activation contrasts feedback and information levels on the gambles. Second, post-survey, the researchers could have asked a question with binary responses to assess what factors influenced the participant's choice of Gamble A and B. In particular, by presenting the binary options of whether loss (fear of it) or pleasure (excitement of it) were incentives. Asking about this would allow me to run a t-test on the incentive levels (loss or pleasure) to assess if those variables affected their emotions about the options and, therefore their choice of Gamble A or B. This would provide further insight into whether the loss aversion or pleasure-seeking psychological frameworks impacted the choices between Gamble A and B. Finally, to incorporate more biological factors into this study, they could also count the pace of the heartbeats for participants based on their problem and Gamble selection to draw correlations for trends and patterns because the biology of decision-making indicates that individuals with stronger interoceptive abilities such as their heart rate perform and manage their emotions better.

# Personal Reflections

My original research question was, How do the participant's responses to the risky-choice problem contrast with known probabilities (certainty) versus unknown probabilities (ambiguity and lottery)? I was interested in this question because Gambles A and B offer different levels of uncertainty and monetary reward. I was curious about the underlying mechanisms that influence such financial decisions and whether there were trends. However, I had to change my research question because I did not have the risky-choice problem choices rate for both Gamble A and B. Instead, I only had bRate. My new research question became, How do the participant's responses to the Gamble B risky-choice problem, with unknown probabilities (ambiguity and lottery), contrast when the participant receives the feedback (`Feedback`) or information (`Amb`) treatment? Despite deviating from my original research question, I still performed my statistical tests and investigated if feedback and information levels impacted the frequency of participants choosing Gamble B, known for its ambiguity and lottery structure. For a future iteration of this project, I would have incorporated a variable that represents the frequency with which participants selected Gamble A.

I chose to study decision-making and judgment in the context of money management because, for my internship at Morgan Stanley in their Investment Management division on the Risk team. The Risk division monitors, assesses, and manages expected and unexpected events risk. Therefore, their team takes and manages risk frequently under volatility across the following functions: credit risk, enterprise risk management, liquidity risk, market risk, model risk management, and operational risk. We will have a week of training about the methods used to quantify and asses risk levels across various divisions, but in this seminar, I wanted to learn about the underlying neuroscience, psychology, and biology behind decision-making and judgment protocols. For example, the firm I will be interning with has numerous articles published about behavioral biases, such as, [Overcoming Behavioral Biases](https://www.morganstanley.com/im/en-us/individual-investor/insights/articles/overcoming-behavioral-biases.html) and [Rational Investing in an Age of Uncertainty](https://www.morganstanley.com/articles/behavioral-finance), and this tells me that they have active conversations about the psychology of investing in addition to the statistical and quantitative methods. In my previous internship this past summer, I also learned that institutional investors use a multidisciplinary (human psychology, financial theory, history, exposure to current events) approach to develop portfolio strategies, so it will be essential for me to to be aware and proactive about my internal biases during the investment management process.

I enjoyed developing a research project and methodology to surround a topic that interests me. The literature and results are relevant to my career interests, so I am eager to apply and share what I learned with my intern cohort and throughout my internship projects. I initially experienced challenges with comprehending the data set and the scale of the variables, but with the support of Professor Dutt, I resolved my questions and worked on a probabilities data set for the first time. I also did not have sufficient variables to respond to my research question, but I adjusted and still produced new insights using my statistical methods since this data was initially used for machine learning and to predict human behavior. I am excited at the prospect of returning to this project or building on it in the future, as machine learning changes the future of investing, and I can have the new experience of running quantitative experiments on the model to measure its accuracy rate of predicting human behavior under risk, ambiguity, and volatility.

# Code Availability

All analysis code for this article is available on GitHub at, [SDS 300 Investigating the Impact of Monetary Rewards on Choice Behavior, Decision Making and Risk Management](https://github.com/michelruizfuentes/SDS300-Final-Project)

# Acknowledgements

I would like to thank Professor Dutt for her support and patience throughout this seminar and research design. I want to thank the Celebrating Collaborations committee for allowing me to present my preliminary findings and gain experience sharing my literature and statistical methods with an audience. Third, I would like to thank the professors in the Statistical and Data Science department that have me previously and have prepared me for this seminar. And lastly, I would like to thank my family and friends.

# References
